{"cells":[{"cell_type":"markdown","metadata":{},"source":["<p style=\"text-align:center\">\n","    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork928-2022-01-01\" target=\"_blank\">\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n","    </a>\n","</p>\n"]},{"cell_type":"markdown","metadata":{},"source":["# **Collecting Job Data Using APIs**\n"]},{"cell_type":"markdown","metadata":{},"source":["Estimated time needed: **45 to 60** minutes\n"]},{"cell_type":"markdown","metadata":{},"source":["## Objectives\n"]},{"cell_type":"markdown","metadata":{},"source":["After completing this lab, you will be able to:\n"]},{"cell_type":"markdown","metadata":{},"source":["*   Collect job data from Jobs API\n","*   Store the collected data into an excel spreadsheet.\n"]},{"cell_type":"markdown","metadata":{},"source":["><strong>Note: Before starting with the assignment make sure to read all the instructions and then move ahead with the coding part.</strong>\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Instructions\n"]},{"cell_type":"markdown","metadata":{},"source":["To run the actual lab, firstly you need to click on the [Jobs_API](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/module%201/Accessing%20Data%20Using%20APIs/Jobs_API.ipynb) notebook link. The file contains flask code which is required to run the Jobs API data.\n","\n","Now, to run the code in the file that opens up follow the below steps.\n","\n","Step1: Download the file. \n","\n","Step2: Upload it on the IBM Watson studio. (If IBM Watson Cloud service does not work in your system, follow the alternate Step 2 below)\n","\n","Step2(alternate): Upload it in your SN labs environment using the upload button which is highlighted in red in the image below:\n","Remember to upload this Jobs_API file in the same folder as your current .ipynb file\n","\n","<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/module%201/Accessing%20Data%20Using%20APIs/Upload.PNG\">\n","\n","Step3:  Run all the cells of the Jobs_API file. (Even if you receive an asterik sign after running the last cell, the code works fine.)\n","\n","If you want to learn more about flask, which is optional, you can click on this link [here](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/module%201/Accessing%20Data%20Using%20APIs/FLASK_API.md.html).\n","\n","Once you run the flask code, you can start with your assignment.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Dataset Used in this Assignment\n","\n","The dataset used in this lab comes from the following source: https://www.kaggle.com/promptcloud/jobs-on-naukricom under the under a **Public Domain license**.\n","\n","> Note: We are using a modified subset of that dataset for the lab, so to follow the lab instructions successfully please use the dataset provided with the lab, rather than the dataset from the original source.\n","\n","The original dataset is a csv. We have converted the csv to json as per the requirement of the lab.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Warm-Up Exercise\n"]},{"cell_type":"markdown","metadata":{},"source":["Before you attempt the actual lab, here is a fully solved warmup exercise that will help you to learn how to access an API.\n"]},{"cell_type":"markdown","metadata":{},"source":["Using an API, let us find out who currently are on the International Space Station (ISS).<br> The API at [http://api.open-notify.org/astros.json](http://api.open-notify.org/astros.json?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork21426264-2021-01-01&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBM-DA0321EN-SkillsNetwork-21426264&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ) gives us the information of astronauts currently on ISS in json format.<br>\n","You can read more about this API at [http://open-notify.org/Open-Notify-API/People-In-Space/](http://open-notify.org/Open-Notify-API/People-In-Space?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork21426264-2021-01-01&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBM-DA0321EN-SkillsNetwork-21426264&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ)\n"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["import requests # you need this module to make an API call\n","import pandas as pd"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["api_url = \"http://api.open-notify.org/astros.json\" # this url gives use the astronaut data"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"ename":"ConnectionError","evalue":"HTTPConnectionPool(host='api.open-notify.org', port=80): Max retries exceeded with url: /astros.json (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002B923BF6310>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)","File \u001b[1;32mc:\\Anaconda3\\envs\\DataScience\\lib\\site-packages\\urllib3\\connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     conn \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mcreate_connection(\n\u001b[0;32m    175\u001b[0m         (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dns_host, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_kw\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    178\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout:\n","File \u001b[1;32mc:\\Anaconda3\\envs\\DataScience\\lib\\site-packages\\urllib3\\util\\connection.py:95\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[39mif\u001b[39;00m err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 95\u001b[0m     \u001b[39mraise\u001b[39;00m err\n\u001b[0;32m     97\u001b[0m \u001b[39mraise\u001b[39;00m socket\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mgetaddrinfo returns an empty list\u001b[39m\u001b[39m\"\u001b[39m)\n","File \u001b[1;32mc:\\Anaconda3\\envs\\DataScience\\lib\\site-packages\\urllib3\\util\\connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m     sock\u001b[39m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 85\u001b[0m sock\u001b[39m.\u001b[39;49mconnect(sa)\n\u001b[0;32m     86\u001b[0m \u001b[39mreturn\u001b[39;00m sock\n","\u001b[1;31mTimeoutError\u001b[0m: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond","\nDuring handling of the above exception, another exception occurred:\n","\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)","File \u001b[1;32mc:\\Anaconda3\\envs\\DataScience\\lib\\site-packages\\urllib3\\connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    715\u001b[0m     conn,\n\u001b[0;32m    716\u001b[0m     method,\n\u001b[0;32m    717\u001b[0m     url,\n\u001b[0;32m    718\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    719\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    720\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    721\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    722\u001b[0m )\n\u001b[0;32m    724\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[39m# mess.\u001b[39;00m\n","File \u001b[1;32mc:\\Anaconda3\\envs\\DataScience\\lib\\site-packages\\urllib3\\connectionpool.py:415\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 415\u001b[0m         conn\u001b[39m.\u001b[39;49mrequest(method, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhttplib_request_kw)\n\u001b[0;32m    417\u001b[0m \u001b[39m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[39m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[39m# With this behaviour, the received response is still readable.\u001b[39;00m\n","File \u001b[1;32mc:\\Anaconda3\\envs\\DataScience\\lib\\site-packages\\urllib3\\connection.py:244\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers)\u001b[0m\n\u001b[0;32m    243\u001b[0m     headers[\u001b[39m\"\u001b[39m\u001b[39mUser-Agent\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m _get_default_user_agent()\n\u001b[1;32m--> 244\u001b[0m \u001b[39msuper\u001b[39;49m(HTTPConnection, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mrequest(method, url, body\u001b[39m=\u001b[39;49mbody, headers\u001b[39m=\u001b[39;49mheaders)\n","File \u001b[1;32mc:\\Anaconda3\\envs\\DataScience\\lib\\http\\client.py:1256\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1255\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1256\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_request(method, url, body, headers, encode_chunked)\n","File \u001b[1;32mc:\\Anaconda3\\envs\\DataScience\\lib\\http\\client.py:1302\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1301\u001b[0m     body \u001b[39m=\u001b[39m _encode(body, \u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1302\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendheaders(body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n","File \u001b[1;32mc:\\Anaconda3\\envs\\DataScience\\lib\\http\\client.py:1251\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1250\u001b[0m     \u001b[39mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1251\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_output(message_body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n","File \u001b[1;32mc:\\Anaconda3\\envs\\DataScience\\lib\\http\\client.py:1011\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1010\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1011\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(msg)\n\u001b[0;32m   1013\u001b[0m \u001b[39mif\u001b[39;00m message_body \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1014\u001b[0m \n\u001b[0;32m   1015\u001b[0m     \u001b[39m# create a consistent interface to message_body\u001b[39;00m\n","File \u001b[1;32mc:\\Anaconda3\\envs\\DataScience\\lib\\http\\client.py:951\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    950\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_open:\n\u001b[1;32m--> 951\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnect()\n\u001b[0;32m    952\u001b[0m \u001b[39melse\u001b[39;00m:\n","File \u001b[1;32mc:\\Anaconda3\\envs\\DataScience\\lib\\site-packages\\urllib3\\connection.py:205\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 205\u001b[0m     conn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[0;32m    206\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_conn(conn)\n","File \u001b[1;32mc:\\Anaconda3\\envs\\DataScience\\lib\\site-packages\\urllib3\\connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[39mexcept\u001b[39;00m SocketError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 186\u001b[0m     \u001b[39mraise\u001b[39;00m NewConnectionError(\n\u001b[0;32m    187\u001b[0m         \u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFailed to establish a new connection: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m e\n\u001b[0;32m    188\u001b[0m     )\n\u001b[0;32m    190\u001b[0m \u001b[39mreturn\u001b[39;00m conn\n","\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x000002B923BF6310>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond","\nDuring handling of the above exception, another exception occurred:\n","\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)","File \u001b[1;32mc:\\Anaconda3\\envs\\DataScience\\lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n","File \u001b[1;32mc:\\Anaconda3\\envs\\DataScience\\lib\\site-packages\\urllib3\\connectionpool.py:798\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    796\u001b[0m     e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, e)\n\u001b[1;32m--> 798\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[0;32m    799\u001b[0m     method, url, error\u001b[39m=\u001b[39;49me, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    801\u001b[0m retries\u001b[39m.\u001b[39msleep()\n","File \u001b[1;32mc:\\Anaconda3\\envs\\DataScience\\lib\\site-packages\\urllib3\\util\\retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[39mif\u001b[39;00m new_retry\u001b[39m.\u001b[39mis_exhausted():\n\u001b[1;32m--> 592\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[39mor\u001b[39;00m ResponseError(cause))\n\u001b[0;32m    594\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mIncremented Retry for (url=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m): \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, url, new_retry)\n","\u001b[1;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='api.open-notify.org', port=80): Max retries exceeded with url: /astros.json (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002B923BF6310>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))","\nDuring handling of the above exception, another exception occurred:\n","\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)","\u001b[1;32me:\\OneDrive\\Desktop\\2 IBM Data Analysis\\9 IBM Data Analyst Capstone Project\\Week1\\collection\\Collecting_Jobs_data_Using_API-Questions (1).ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/OneDrive/Desktop/2%20IBM%20Data%20Analysis/9%20IBM%20Data%20Analyst%20Capstone%20Project/Week1/collection/Collecting_Jobs_data_Using_API-Questions%20%281%29.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(api_url)\n","File \u001b[1;32mc:\\Anaconda3\\envs\\DataScience\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[1;32mc:\\Anaconda3\\envs\\DataScience\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[1;32mc:\\Anaconda3\\envs\\DataScience\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n","File \u001b[1;32mc:\\Anaconda3\\envs\\DataScience\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n","File \u001b[1;32mc:\\Anaconda3\\envs\\DataScience\\lib\\site-packages\\requests\\adapters.py:519\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, _SSLError):\n\u001b[0;32m    516\u001b[0m         \u001b[39m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[0;32m    517\u001b[0m         \u001b[39mraise\u001b[39;00m SSLError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m--> 519\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m    521\u001b[0m \u001b[39mexcept\u001b[39;00m ClosedPoolError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    522\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n","\u001b[1;31mConnectionError\u001b[0m: HTTPConnectionPool(host='api.open-notify.org', port=80): Max retries exceeded with url: /astros.json (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002B923BF6310>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))"]}],"source":["response = requests.get(api_url) # Call the API using the get method and store the\n","                                # output of the API call in a variable called response."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if response.ok:             # if all is well() no errors, no network timeouts)\n","    data = response.json()  # store the result in json format in a variable called data\n","                            # the variable data is of type dictionary."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'message': 'success', 'people': [{'name': 'Jasmin Moghbeli', 'craft': 'ISS'}, {'name': 'Andreas Mogensen', 'craft': 'ISS'}, {'name': 'Satoshi Furukawa', 'craft': 'ISS'}, {'name': 'Konstantin Borisov', 'craft': 'ISS'}, {'name': 'Oleg Kononenko', 'craft': 'ISS'}, {'name': 'Nikolai Chub', 'craft': 'ISS'}, {'name': \"Loral O'Hara\", 'craft': 'ISS'}], 'number': 7}\n"]}],"source":["print(data)   # print the data just to check the output or for debugging"]},{"cell_type":"markdown","metadata":{},"source":["Print the number of astronauts currently on ISS.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["7\n"]}],"source":["print(data.get('number'))"]},{"cell_type":"markdown","metadata":{},"source":["Print the names of the astronauts currently on ISS.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 7 astronauts on ISS\n","And their names are :\n","Jasmin Moghbeli\n","Andreas Mogensen\n","Satoshi Furukawa\n","Konstantin Borisov\n","Oleg Kononenko\n","Nikolai Chub\n","Loral O'Hara\n"]}],"source":["astronauts = data.get('people')\n","print(\"There are {} astronauts on ISS\".format(len(astronauts)))\n","print(\"And their names are :\")\n","for astronaut in astronauts:\n","    print(astronaut.get('name'))"]},{"cell_type":"markdown","metadata":{},"source":["Hope the warmup was helpful. Good luck with your next lab!\n"]},{"cell_type":"markdown","metadata":{},"source":["## Lab: Collect Jobs Data using Jobs API\n"]},{"cell_type":"markdown","metadata":{},"source":["### Objective: Determine the number of jobs currently open for various technologies  and for various locations\n"]},{"cell_type":"markdown","metadata":{},"source":["Collect the number of job postings for the following locations using the API:\n","\n","* Los Angeles\n","* New York\n","* San Francisco\n","* Washington DC\n","* Seattle\n","* Austin\n","* Detroit\n"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["#Import required libraries\n","import requests\n","import pandas as pd\n","import json"]},{"cell_type":"markdown","metadata":{},"source":["#### Write a function to get the number of jobs for the Python technology.<br>\n","> Note: While using the lab you need to pass the **payload** information for the **params** attribute in the form of **key** **value** pairs.\n","  Refer the ungraded **rest api lab** in the course **Python for Data Science, AI & Development**  <a href=\"https://www.coursera.org/learn/python-for-applied-data-science-ai/ungradedLti/P6sW8/hands-on-lab-access-rest-apis-request-http?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork928-2022-01-01\">link</a>\n","  \n"," ##### The keys in the json are \n"," * Job Title\n"," \n"," * Job Experience Required\n"," \n"," * Key Skills\n"," \n"," * Role Category\n"," \n"," * Location\n"," \n"," * Functional Area\n"," \n"," * Industry\n"," \n"," * Role \n"," \n","You can also view  the json file contents  from the following <a href = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/module%201/Accessing%20Data%20Using%20APIs/jobs.json\">json</a> URL.\n"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[],"source":["api_url= \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/module%201/Accessing%20Data%20Using%20APIs/jobs.json\"\n","response = requests.get(api_url)\n","data=response.json()\n","\n","def get_number_of_jobs_T(technology):\n","    number_of_jobs = 0\n","    if data:\n","     for job in data:\n","        key_skills = job.get(\"Key Skills\",\"\")\n","        if technology.lower() in key_skills.lower():\n","            number_of_jobs += 1\n","    return technology,number_of_jobs"]},{"cell_type":"markdown","metadata":{},"source":["Calling the function for Python and checking if it works.\n"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[{"data":{"text/plain":["('Python', 1173)"]},"execution_count":67,"metadata":{},"output_type":"execute_result"}],"source":["get_number_of_jobs_T(\"Python\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Write a function to find number of jobs in US for a location of your choice\n"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[],"source":["def get_number_of_jobs_L(location):\n","    number_of_jobs = 0\n","    Location = location\n","    if data:\n","        for loc in data:\n","            location_data = loc.get(\"Location\")\n","            if location_data and location.lower() in location_data.lower():\n","             number_of_jobs +=1\n","    return Location,number_of_jobs\n","\n","    \n","    #your coe goes here\n","    return location,number_of_jobs"]},{"cell_type":"markdown","metadata":{},"source":["Call the function for Los Angeles and check if it is working.\n","\n","\n"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[{"data":{"text/plain":["('Los Angeles', 640)"]},"execution_count":61,"metadata":{},"output_type":"execute_result"}],"source":["#your code goes here\n","get_number_of_jobs_L(\"Los Angeles\")"]},{"cell_type":"markdown","metadata":{},"source":["### Store the results in an excel file\n"]},{"cell_type":"markdown","metadata":{},"source":["Call the API for all the given technologies above and write the results in an excel spreadsheet.\n"]},{"cell_type":"markdown","metadata":{},"source":["If you do not know how create excel file using python, double click here for **hints**.\n","\n","<!--\n","\n","from openpyxl import Workbook        # import Workbook class from module openpyxl\n","wb=Workbook()                        # create a workbook object\n","ws=wb.active                         # use the active worksheet\n","ws.append(['Country','Continent'])   # add a row with two columns 'Country' and 'Continent'\n","ws.append(['Eygpt','Africa'])        # add a row with two columns 'Egypt' and 'Africa'\n","ws.append(['India','Asia'])          # add another row\n","ws.append(['France','Europe'])       # add another row\n","wb.save(\"countries.xlsx\")            # save the workbook into a file called countries.xlsx\n","\n","\n","-->\n"]},{"cell_type":"markdown","metadata":{},"source":["Create a python list of all locations for which you need to find the number of jobs postings.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["locations = [\n","    \"Los Angeles\",\n","    \"New York\",\n","    \"San Francisco\",\n","    \"Washington DC\",\n","    \"Seattle\",\n","    \"Austin\",\n","    \"Detroit\"\n","]\n","\n","# You can now iterate through this list to find the number of job postings for each location.\n"]},{"cell_type":"markdown","metadata":{},"source":["Import libraries required to create excel spreadsheet\n"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[],"source":["# your code goes here\n","import pandas as pd\n","import openpyxl\n","from openpyxl import Workbook"]},{"cell_type":"markdown","metadata":{},"source":["Create a workbook and select the active worksheet\n"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[],"source":["# your code goes here\n","\n","# Create a new workbook\n","workbook = openpyxl.Workbook()\n","\n","# Select the active worksheet (the first worksheet by default)\n","worksheet = workbook.active\n","\n","# You can also give the worksheet a custom name\n","worksheet.title = \"Job_listings\"\n","\n","# Now, you can work with the selected worksheet (e.g., add data, format cells, etc.)\n","\n","# Save the workbook to a file\n","workbook.save(\"Job_listings.xlsx\")\n","\n","# Don't forget to close the workbook when you're done\n","workbook.close()\n"]},{"cell_type":"markdown","metadata":{},"source":["Find the number of jobs postings for each of the location in the above list.\n","Write the Location name and the number of jobs postings into the excel spreadsheet.\n"]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[],"source":["#your code goes here\n","import openpyxl\n","import requests\n","\n","# Define the API URL\n","api_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/module%201/Accessing%20Data%20Using%20APIs/jobs.json\"\n","\n","# Send a GET request to the API\n","response = requests.get(api_url)\n","data = response.json()\n","\n","# Create a list of locations\n","locations = [\"Los Angeles\", \"New York\", \"San Francisco\", \"Washington DC\", \"Seattle\", \"Austin\", \"Detroit\"]\n","\n","# Open the existing workbook\n","workbook = openpyxl.load_workbook(\"Job_listings.xlsx\")\n","worksheet = workbook.active\n","\n","# Write headers to the worksheet (if not already present)\n","if \"Location\" not in [cell.value for cell in worksheet[1]]:\n","    worksheet[\"A1\"] = \"Location\"\n","    worksheet[\"B1\"] = \"Number of Jobs\"\n","\n","# Find the number of job postings for each location and append to the worksheet\n","for row, location in enumerate(locations, start=2):\n","    number_of_jobs = sum(1 for job in data if job.get(\"Location\") == location)\n","    worksheet.cell(row=row, column=1, value=location)\n","    worksheet.cell(row=row, column=2, value=number_of_jobs)\n","\n","# Save the updated workbook\n","workbook.save(\"Job_listings.xlsx\")\n","\n","# Close the workbook\n","workbook.close()\n"]},{"cell_type":"markdown","metadata":{},"source":["Save into an excel spreadsheet named 'job-postings.xlsx'.\n"]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Job_listings.xlsx copied to job-postings.xlsx\n"]}],"source":["import openpyxl\n","\n","# Open \"Job_listings.xlsx\"\n","input_file = \"Job_listings.xlsx\"\n","output_file = \"job-postings.xlsx\"\n","\n","# Load the existing workbook\n","workbook = openpyxl.load_workbook(input_file)\n","\n","# Create a new workbook\n","new_workbook = openpyxl.Workbook()\n","new_workbook.remove(new_workbook.active)  # Remove the default worksheet\n","\n","# Copy sheets from the old workbook to the new one\n","for sheet_name in workbook.sheetnames:\n","    old_sheet = workbook[sheet_name]\n","    new_sheet = new_workbook.create_sheet(sheet_name)\n","\n","    for row in old_sheet.iter_rows():\n","        new_row = [cell.value for cell in row]\n","        new_sheet.append(new_row)\n","\n","# Save the new workbook as \"job-postings.xlsx\"\n","new_workbook.save(output_file)\n","\n","# Close both workbooks\n","workbook.close()\n","new_workbook.close()\n","\n","print(f\"{input_file} copied to {output_file}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["#### In the similar way, you can try for below given technologies and results  can be stored in an excel sheet.\n"]},{"cell_type":"markdown","metadata":{},"source":["Collect the number of job postings for the following languages using the API:\n","\n","*   C\n","*   C#\n","*   C++\n","*   Java\n","*   JavaScript\n","*   Python\n","*   Scala\n","*   Oracle\n","*   SQL Server\n","*   MySQL Server\n","*   PostgreSQL\n","*   MongoDB\n"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Job counts updated successfully.\n"]}],"source":["# your code goes here\n","import openpyxl\n","import requests\n","\n","# Load the existing workbook\n","workbook = openpyxl.load_workbook(\"job-postings.xlsx\")\n","\n","# Define the sheet name\n","sheet_name = \"Jobs_by_technology\"\n","\n","# Check if the sheet already exists, and if so, delete it\n","if sheet_name in workbook.sheetnames:\n","    del workbook[sheet_name]\n","\n","# Create a new sheet\n","new_sheet = workbook.create_sheet(sheet_name)\n","\n","# Add headers to the new sheet\n","new_sheet.cell(row=1, column=1, value=\"Technology\")\n","new_sheet.cell(row=1, column=2, value=\"Job Count\")\n","\n","# Define the technology list\n","technology_list = [\n","    \"C\",\n","    \"C#\",\n","    \"C++\",\n","    \"Java\",\n","    \"JavaScript\",\n","    \"Python\",\n","    \"Scala\",\n","    \"Oracle\",\n","    \"SQL Server\",\n","    \"MySQL Server\",\n","    \"PostgreSQL\",\n","    \"MongoDB\",\n","]\n","\n","# Fetch job data from the API URL\n","api_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/module%201/Accessing%20Data%20Using%20APIs/jobs.json\"\n","response = requests.get(api_url)\n","\n","if response.status_code == 200:\n","    data = response.json()\n","\n","    # Create a dictionary to count jobs by technology\n","    job_counts = {tech: 0 for tech in technology_list}\n","\n","    # Count jobs for each technology\n","    for job in data:\n","        for tech in technology_list:\n","            key_skills = job.get(\"Key Skills\", \"\").lower()\n","            if tech.lower() in key_skills:\n","                job_counts[tech] += 1\n","\n","    # Populate the new sheet with technology names and job counts\n","    for row, tech in enumerate(technology_list, start=2):\n","        new_sheet.cell(row=row, column=1, value=tech)\n","        new_sheet.cell(row=row, column=2, value=job_counts[tech])\n","\n","    # Save the modified workbook\n","    workbook.save(\"job-postings.xlsx\")\n","\n","    print(\"Job counts updated successfully.\")\n","else:\n","    print(\"Failed to retrieve job data from the API.\")\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Author\n"]},{"cell_type":"markdown","metadata":{},"source":["Ayushi Jain\n"]},{"cell_type":"markdown","metadata":{},"source":["### Other Contributors\n"]},{"cell_type":"markdown","metadata":{},"source":["Rav Ahuja\n","\n","Lakshmi Holla\n","\n","Malika\n"]},{"cell_type":"markdown","metadata":{},"source":["## Change Log\n"]},{"cell_type":"markdown","metadata":{},"source":["| Date (YYYY-MM-DD) | Version | Changed By        | Change Description                 |\n","| ----------------- | ------- | ----------------- | ---------------------------------- | \n","| 2022-01-19        | 0.3     | Lakshmi Holla        | Added changes in the markdown      |\n","| 2021-06-25        | 0.2     | Malika            | Updated GitHub job json link       |\n","| 2020-10-17        | 0.1     | Ramesh Sannareddy | Created initial version of the lab |\n"]},{"cell_type":"markdown","metadata":{},"source":["Copyright © 2022 IBM Corporation. All rights reserved. \n"]}],"metadata":{"kernelspec":{"display_name":"DataScience","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"}},"nbformat":4,"nbformat_minor":4}
